{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP for Telco Data (logs) Anonymization**"
      ],
      "metadata": {
        "id": "jKg-moELDMq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To anonymize Personally Identifiable Information (PII) from log files, the first step is to identifying PII.\n",
        "This can be achieved through the utilization of various methods, such as:\n",
        "\n",
        "\n",
        "*   1. Regular Expressions (Regex)\n",
        "*   2. Presidio Lib\n",
        "*   3. NLP Model\n",
        "*   4. Deep Learning (Custom NLP Model)"
      ],
      "metadata": {
        "id": "3CdVDmUrOydB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**1.   Regular Expressions (Regex):**\n",
        "\n"
      ],
      "metadata": {
        "id": "fpOZtx7mUSRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B1ltKmsGj3zU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Defining regular expressions for different types of PII\n",
        "ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'\n",
        "username_pattern = r'\\buser\\s+\\w+\\b'\n",
        "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "userid_pattern = r'\\buser(ID)?\\s+\\d+\\b'\n",
        "\n",
        "# Reading the log file\n",
        "with open('/content/Linux_2k.log', 'r') as file:\n",
        "    log_data = file.read()\n",
        "\n",
        "# Anonymizing IP addresses\n",
        "log_data_anonymized = re.sub(ip_pattern, 'xxx.xxx.xxx.xxx', log_data)\n",
        "\n",
        "# Anonymizing usernames\n",
        "log_data_anonymized = re.sub(username_pattern, 'user XXX', log_data_anonymized)\n",
        "\n",
        "# Anonymizing email addresses\n",
        "log_data_anonymized = re.sub(email_pattern, 'email@example.com', log_data_anonymized)\n",
        "\n",
        "# Anonymizing user IDs\n",
        "log_data_anonymized = re.sub(userid_pattern, 'user ID XXX', log_data_anonymized)\n",
        "\n",
        "with open('re_anonymized.txt', 'w') as file:\n",
        "    file.write(log_data_anonymized)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Limitations of regex-based PII identification:\n",
        "\n",
        "*   Limited accuracy due to inability to capture all variations of PII.\n",
        "*   Lack of context sensitivity, leading to false positives or negatives.\n",
        "*   Difficulty in maintenance and handling variability in PII formats.\n",
        "*   Inability to handle nested structures and overlook encrypted data."
      ],
      "metadata": {
        "id": "e2sgdtWZUxSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Presidio Lib:**"
      ],
      "metadata": {
        "id": "ZMrLU3mvU9An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install presidio-analyzer presidio-anonymizer"
      ],
      "metadata": {
        "id": "jVzIPLcNWF9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2142b01-178f-495f-fb9c-fb8a75a9490c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio-analyzer\n",
            "  Downloading presidio_analyzer-2.2.354-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting presidio-anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.354-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (3.7.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (2023.12.25)\n",
            "Collecting tldextract (from presidio-analyzer)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (6.0.1)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer)\n",
            "  Downloading phonenumbers-8.13.34-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome>=3.10.1 (from presidio-anonymizer)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer) (1.25.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio-analyzer) (3.6)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer)\n",
            "  Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio-analyzer) (3.13.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio-analyzer) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio-analyzer) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio-analyzer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio-analyzer) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.4.4->presidio-analyzer) (2.1.5)\n",
            "Installing collected packages: phonenumbers, pycryptodome, requests-file, presidio-anonymizer, tldextract, presidio-analyzer\n",
            "Successfully installed phonenumbers-8.13.34 presidio-analyzer-2.2.354 presidio-anonymizer-2.2.354 pycryptodome-3.20.0 requests-file-2.0.0 tldextract-5.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "# Read log file\n",
        "with open(\"/content/Linux_2k.log\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "\n",
        "# Initialize the analyzer engine\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Analyze text for PII\n",
        "results = analyzer.analyze(text=text, entities=[], language='en')\n",
        "\n",
        "# Initialize the anonymizer engine\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "# Anonymize PII in text\n",
        "anonymized_result = anonymizer.anonymize(text=text, analyzer_results=results)\n",
        "\n",
        "# Get the anonymized text from the result\n",
        "#anonymized_text = anonymized_result.anonymized_text\n",
        "\n",
        "# Write anonymized data to a new file\n",
        "with open(\"Presidio_anonymized.txt\", \"w\") as output_file:\n",
        "    output_file.write(anonymized_result.text)\n"
      ],
      "metadata": {
        "id": "nQv94AY5VOya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f017c1d5-8132-4269-d384-b68c09880c3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:configuration file /usr/local/lib/python3.10/dist-packages/conf/default.yaml not found.  Using default config: {'nlp_engine_name': 'spacy', 'models': [{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]}.\n",
            "WARNING:presidio-analyzer:configuration file is missing 'ner_model_configuration'. Using default\n",
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:Model en_core_web_lg is not installed. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitations of Presidio-based PII identification:\n",
        "\n",
        "*   Context Sensitivity: Presidio may struggle with context-dependent PII, such as ambiguous terms like \"address\" or \"credit\", leading to potential false positives or negatives.\n",
        "*   Customization Complexity: Tailoring Presidio to specific data types or domains requires considerable effort, potentially hindering its adaptability in diverse environments.\n",
        "*   Performance Overhead: Analyzing large datasets with Presidio could incur significant computational overhead due to its rule-based and machine learning-based processing.\n",
        "*   Language Dependency: Presidio's effectiveness may vary across languages, as it relies on language-specific models and dictionaries, limiting its applicability in multilingual contexts.\n",
        "\n"
      ],
      "metadata": {
        "id": "LfO2lxOiXpjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. NLP Model:**"
      ],
      "metadata": {
        "id": "rO3IIDrTYND3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a function to anonymize PII\n",
        "def anonymize_pii(text):\n",
        "    doc = nlp(text)\n",
        "    anonymized_text = []\n",
        "    for token in doc:\n",
        "        if token.ent_type_ in [\"PERSON\", \"GPE\", \"ORG\", \"CARDINAL\", \"NORP\", \"FAC\"]:\n",
        "            anonymized_text.append(token.ent_type_)\n",
        "        else:\n",
        "            anonymized_text.append(token.text)\n",
        "    return \" \".join(anonymized_text)\n",
        "\n",
        "# Read the log file\n",
        "with open(\"/content/Linux_2k.log\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Anonymize PII in the text\n",
        "anonymized_text = anonymize_pii(text)\n",
        "\n",
        "# Write anonymized data to a new file\n",
        "with open(\"NLP_anonymized.txt\", \"w\") as output_file:\n",
        "    output_file.write(anonymized_text)\n"
      ],
      "metadata": {
        "id": "FARnU_E1YT1U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this approach, we utilized spaCy, a natural language processing (NLP) library, for Named Entity Recognition (NER). The code identifies entities such as names, dates, locations, and organizations within the dataset and replaces them with generic labels, effectively anonymizing personally identifiable information (PII) without resorting to regular expressions."
      ],
      "metadata": {
        "id": "0Qd6-0-nOJH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitations of NLP(spaCy)-based PII identification:\n",
        "*  Accuracy depends on NER precision, varying with dataset nuances.\n",
        "*   Limited context understanding may lead to entity misidentification.\n",
        "*  Effectiveness may be hindered in languages with immature NLP support."
      ],
      "metadata": {
        "id": "GBdiEgZ6OLwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Deep Learning (Custom NLP Model)**"
      ],
      "metadata": {
        "id": "oaI923rhQVd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To accomplish this task, we require a dataset with clear labels to train a deep learning model designed to identify Personally Identifiable Information (PII) within log files.\n",
        "\n",
        "One effective method involves leveraging a Natural Language Processing (NLP) model built upon Recurrent Neural Networks (RNNs). This approach can significantly enhance the precision of PII detection.\n",
        "\n",
        "Below is an illustrative model demonstrating this approach:\n",
        "\n",
        "https://www.kaggle.com/code/awsaf49/pii-data-detection-kerasnlp-starter-notebook/notebook#%F0%9F%93%A9-|-Submission"
      ],
      "metadata": {
        "id": "nm5uIsDjRVMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Function to tokenize a line into words\n",
        "def tokenize_line(line):\n",
        "    return line.split()\n",
        "\n",
        "# Function to read the log file, tokenize each line, and write to JSON\n",
        "def log_to_json(log_file, json_file):\n",
        "    # Open log file for reading\n",
        "    with open(log_file, 'r') as infile:\n",
        "        # Initialize list to store JSON objects\n",
        "        json_data = []\n",
        "\n",
        "        # Process each line in the log file\n",
        "        for line_number, line in enumerate(infile):\n",
        "            # Tokenize the line into words\n",
        "            words = tokenize_line(line)\n",
        "\n",
        "            # Determine trailing whitespace\n",
        "            trailing_whitespace = [c.isspace() for c in line.strip()]\n",
        "\n",
        "            # Create JSON object with tokenized words and trailing whitespace\n",
        "            json_obj = {\n",
        "                \"line\": line_number,  # Assign unique identifier to each line\n",
        "                \"full_text\": line.strip(),  # Store original line\n",
        "                \"tokens\": words,         # Store tokenized words\n",
        "                \"trailing_whitespace\": trailing_whitespace  # Store trailing whitespace\n",
        "            }\n",
        "\n",
        "            # Append JSON object to list\n",
        "            json_data.append(json_obj)\n",
        "\n",
        "    # Write list of JSON objects to JSON file\n",
        "    with open(json_file, 'w') as outfile:\n",
        "        json.dump(json_data, outfile, indent=4)\n",
        "\n",
        "# Example usage:\n",
        "log_file = 'Linux_2k.log'\n",
        "json_file = 'tokenized_data.json'\n",
        "log_to_json(log_file, json_file)\n"
      ],
      "metadata": {
        "id": "V3EFMra0Qa_u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to label tokens as PII or not\n",
        "def label_tokens(data):\n",
        "    labeled_data = []\n",
        "    for log in data:\n",
        "        tokens = log[\"tokens\"]\n",
        "        text = \" \".join(tokens)\n",
        "        doc = nlp(text)\n",
        "        pii_labels = [True if ent.label_ == \"MISC\" else False for ent in doc.ents]\n",
        "        labeled_data.append({\"line\": log[\"line\"], \"tokens\": tokens, \"pii_labels\": pii_labels})\n",
        "    return labeled_data\n",
        "\n",
        "# Write labeled data to output file\n",
        "def write_labeled_data(data, output_file):\n",
        "    doc_bin = DocBin()\n",
        "    for log in data:\n",
        "        tokens = log[\"tokens\"]\n",
        "        pii_labels = log[\"pii_labels\"]\n",
        "        text = \" \".join(tokens)\n",
        "        doc = nlp.make_doc(text)\n",
        "        for token, pii_label in zip(doc, pii_labels):\n",
        "            if pii_label:\n",
        "                doc.ents = [(token.idx, token.idx + len(token), \"MISC\")]\n",
        "        doc_bin.add(doc)\n",
        "    doc_bin.to_disk(output_file)\n",
        "\n",
        "\n",
        "data = json.load(open(\"/content/tokenized_data.json\"))\n",
        "\n",
        "# Label tokens as PII or not\n",
        "labeled_data = label_tokens(data)\n",
        "\n",
        "# Write labeled data to output file\n",
        "output_file = \"labeled_data.spacy\"\n",
        "write_labeled_data(labeled_data, output_file)\n"
      ],
      "metadata": {
        "id": "jfpg_-d5bxt6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:"
      ],
      "metadata": {
        "id": "pbuRe4vlSmTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** Is it possible to anonymize the dataset using NLP?\n",
        "\n",
        "**Ans:** NLP techniques can definitely help anonymize datasets. By splitting text into tokens, recognizing named entities, and masking sensitive info, we can keep data private while maintaining its usefulness. Custom rules and synthetic data generation are also handy.\n",
        "So Yes, NLP is a solid tool for keeping data safe!"
      ],
      "metadata": {
        "id": "-RvfT1T5SzWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** Does it ‘successfully’ anonymize?\n",
        "\n",
        "**Ans:** Absolutely! Custom models tailored for log data can take anonymization to the next level. By leveraging techniques like RNNs, which grasp context better, we can ensure even more accurate anonymization of PII in logs. It's all about fine-tuning for the task at hand!"
      ],
      "metadata": {
        "id": "-K6TWyArTcOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** How easy is it to use NLP?\n",
        "\n",
        "**Ans:** NLP can be straightforward when using pre-trained models or libraries. They offer easy-to-use interfaces and documentation. However, customization and fine-tuning can make things more complex, requiring a deeper understanding and additional effort."
      ],
      "metadata": {
        "id": "1zdrxrC4UN5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** Does it make sense to use NLP?\n",
        "\n",
        "**Ans:**\n",
        "Indeed, NLP stands out as an invaluable tool for detecting PII. Given the dynamic nature of PII and the paramount importance of privacy, accuracy in detection and anonymization is crucial. In this regard, NLP emerges as the optimal choice, offering the capabilities needed to ensure precise identification and effective anonymization of sensitive information."
      ],
      "metadata": {
        "id": "nDR3Ql6BUw2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** Are the available libraries good enough?\n",
        "\n",
        "**Ans:** Yes, in a broad sense, the available libraries for NLP perform well. However, for specific tasks like processing log files, they require fine-tuning and customization. For instance, they may overlook the importance of handling IP addresses in logs, which is a critical aspect. Therefore, for such specialized tasks and others like them, custom solutions or the development of custom libraries may be necessary."
      ],
      "metadata": {
        "id": "UGoLAJENVfqO"
      }
    }
  ]
}